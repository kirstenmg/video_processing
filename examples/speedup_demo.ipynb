{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combo_dataloader import ComboDataLoader, ComboDLTransform, DataLoaderType\n",
    "import torchvision\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up video inputs and model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load in video paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file_path = \"/home/maureen/kinetics/kinetics400_10classes/annotations/val.csv\"\n",
    "video_base_path = \"/home/maureen/kinetics/kinetics400_10classes\"\n",
    "video_paths = []\n",
    "with open(annotation_file_path, 'r') as annotation_file:\n",
    "\tfor i, line in enumerate(annotation_file):\n",
    "\t\tif i != 0: # skip column headers\n",
    "\t\t\tline = annotation_file.readline()\n",
    "\t\t\tlabel, youtube_id, time_start, time_end, split, is_cc = line.strip().split(',')\n",
    "\t\t\tvpath = f'{video_base_path}/{split}/{youtube_id}_{int(time_start):06d}_{int(time_end):06d}.mp4'\n",
    "\t\t\tvideo_paths.append(vpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ComboDLTransform(\n",
    "\t\tcrop=112,\n",
    "\t\tmean=[0.43216, 0.394666, 0.37645],\n",
    "\t\tstd=[0.22803 , 0.22145 , 0.216989],\n",
    "\t\tshort_side_scale=128\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing dataloader configurations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using only a PyTorch dataloader**\n",
    "\n",
    "This configuration creates a single subprocess for a pytorch dataloader to load video inputs. Note the `num_workers` kwarg, which will get passed to the torch DataLoader constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "dl = ComboDataLoader(\n",
    "\t\tdataloaders=[DataLoaderType.PYTORCH],\n",
    "\t\tdataloader_portions=[1],\n",
    "\t\tvideo_paths=video_paths,\n",
    "\t\ttransform=transform,\n",
    "\t\tstride=2,\n",
    "\t\tstep=32,\n",
    "\t\tsequence_length=16,\n",
    "\t\tfps=32,\n",
    "\t\tbatch_size=8,\n",
    "\t\tpytorch_dataloader_kwargs={\"num_workers\": 10},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time how long it takes to process all the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.3154000339564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in dl:\n",
    "    pass\n",
    "pytorch_time = time.perf_counter() - start\n",
    "pytorch_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using only a DALI dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ComboDataLoader(\n",
    "\t\tdataloaders=[DataLoaderType.DALI],\n",
    "\t\tdataloader_portions=[1],\n",
    "\t\tvideo_paths=video_paths,\n",
    "\t\ttransform=transform,\n",
    "\t\tstride=2,\n",
    "\t\tstep=32,\n",
    "\t\tsequence_length=16,\n",
    "\t\tfps=32,\n",
    "\t\tbatch_size=8,\n",
    "\t\tdali_pipeline_kwargs={\"num_threads\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[/opt/dali/dali/operators/reader/loader/video_loader.h:180] ``file_list_include_preceding_frame`` uses the default value False. In future releases, the default value will be changed to True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101.49571724503767"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in dl:\n",
    "    pass\n",
    "dali_time = time.perf_counter() - start\n",
    "dali_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the optimal combination of DALI and PyTorch**\n",
    "\n",
    "Based on the times measured above, we allocate the videos in an optimal split between DALI and PyTorch to take advantage of concurrency between the CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.867516002121846"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dali_portion = int(round(pytorch_time / (pytorch_time + dali_time) * 100))\n",
    "pytorch_portion = int(round(dali_time / (pytorch_time + dali_time) * 100))\n",
    "\n",
    "# Expected time with these portions\n",
    "# We won't get this ideal time, since there is overhead\n",
    "dali_portion / 100 * dali_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "dl = ComboDataLoader(\n",
    "\t\tdataloaders=[DataLoaderType.PYTORCH, DataLoaderType.DALI],\n",
    "\t\tdataloader_portions=[pytorch_portion, dali_portion],\n",
    "\t\tvideo_paths=video_paths,\n",
    "\t\ttransform=transform,\n",
    "\t\tstride=2,\n",
    "\t\tstep=32,\n",
    "\t\tsequence_length=16,\n",
    "\t\tfps=32,\n",
    "\t\tbatch_size=8,\n",
    "\t\tpytorch_dataloader_kwargs={\"num_workers\": 10},\n",
    "\t\tdali_pipeline_kwargs={\"num_threads\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[/opt/dali/dali/operators/reader/loader/video_loader.h:180] ``file_list_include_preceding_frame`` uses the default value False. In future releases, the default value will be changed to True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70.62431819702033"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in dl:\n",
    "    pass\n",
    "end = time.perf_counter() - start\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using PyTorch with a Decord backend**\n",
    "\n",
    "Using decord, we can push the resize down to the decoding step to get over 2x speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "dl = ComboDataLoader(\n",
    "\t\tdataloaders=[DataLoaderType.PYTORCH],\n",
    "\t\tdataloader_portions=[1],\n",
    "\t\tvideo_paths=video_paths,\n",
    "\t\ttransform=transform,\n",
    "\t\tstride=2,\n",
    "\t\tstep=32,\n",
    "\t\tsequence_length=16,\n",
    "\t\tfps=32,\n",
    "\t\tbatch_size=8,\n",
    "\t\tpytorch_dataloader_kwargs={\"num_workers\": 10},\n",
    "\t\tpytorch_dataset_kwargs=dict(decoder=\"decord\", short_side_scale=128),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.828518219990656"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in dl:\n",
    "    pass\n",
    "pytorch_decord_time = time.perf_counter() - start\n",
    "pytorch_decord_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.762119340924889"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_time / pytorch_decord_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the optimal combination of DALI and PyTorch with a Decord backend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.403843656160173"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dali_portion = int(round(pytorch_decord_time / (pytorch_decord_time + dali_time) * 100))\n",
    "pytorch_portion = int(round(dali_time / (pytorch_decord_time + dali_time) * 100))\n",
    "\n",
    "# Expected time with these portions\n",
    "dali_portion / 100 * dali_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "dl = ComboDataLoader(\n",
    "\t\tdataloaders=[DataLoaderType.PYTORCH, DataLoaderType.DALI],\n",
    "\t\tdataloader_portions=[pytorch_portion, dali_portion],\n",
    "\t\tvideo_paths=video_paths,\n",
    "\t\ttransform=transform,\n",
    "\t\tstride=2,\n",
    "\t\tstep=32,\n",
    "\t\tsequence_length=16,\n",
    "\t\tfps=32,\n",
    "\t\tbatch_size=8,\n",
    "\t\tpytorch_dataloader_kwargs={\"num_workers\": 10},\n",
    "\t\tpytorch_dataset_kwargs=dict(decoder=\"decord\", short_side_scale=128),\n",
    "\t\tdali_pipeline_kwargs={\"num_threads\": 10},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[/opt/dali/dali/operators/reader/loader/video_loader.h:180] ``file_list_include_preceding_frame`` uses the default value False. In future releases, the default value will be changed to True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.9872514490271"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in dl:\n",
    "    pass\n",
    "end = time.perf_counter() - start\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.187317125287289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speedup \n",
    "pytorch_time / end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
